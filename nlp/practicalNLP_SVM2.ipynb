{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GHnDE3OC6lrl"},"outputs":[],"source":["##### 데이터 다운로드\n","!pip install datasets   # Package install\n","\n","from datasets import load_dataset   # Huggingface 데이터셋 패키지 import\n","data = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드"]},{"cell_type":"code","source":["##### 데이터 구조 훑어보기\n","# print(\"Data type: \", type(data))    # 데이터 타입 확인\n","# print(\"Data structure: \", data)     # 데이터 구조 확인\n","# print(\"Data keys: \", data.keys())   # 데이터 키 확인\n","\n","print(data['train'][0])   # 실제 데이터 확인"],"metadata":{"id":"8_NM2aMmCjkA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 테스트 세트 만들기\n","train_data = data['train']\n","dev_data = data['validation']\n","test_data = data['test']\n","\n","#print(train_data)\n","#print(dev_data)\n","#print(test_data)"],"metadata":{"id":"IqbCh4yMCiEv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 텍스트 데이터 특성\n","# import matplotlib.pyplot as plt\n","# plt.hist(data['train']['label'], color='red')\n","# plt.show()\n","# plt.hist(data['validation']['label'], color='blue')\n","# plt.show()\n","# plt.hist(data['test']['label'], color='green')\n","# plt.show()"],"metadata":{"id":"NSi7J4fvCfRd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 하는 법 구현)\n","from sklearn.feature_extraction.text import CountVectorizer       # CountVectorizer: Bag of words 벡터화 구현을 하기 위한 클래스\n","\n","vectorizer = CountVectorizer()      # 데이터를 벡터화 해주는 모델 \n","vectorizer.fit(train_data['text'])  # 텍스트 문서 모음을 토큰 수의 행렬로 변환\n","\n","print(vectorizer.vocabulary_)       # 텍스트 문서에 나타난 어휘의 집합을 출력\n","print(len(vectorizer.vocabulary_))  # 텍스트 문서에 나타난 어휘 집합의 길이를 출력\n","\n","train_vectors = vectorizer.transform(train_data['text'])    # 학습 데이터를 숫자로 변환\n","dev_vectors = vectorizer.transform(dev_data['text'])        # 검증 데이터를 숫자로 변환\n","test_vectors = vectorizer.transform(test_data['text'])      # 테스트 데이터를 숫자로 변환\n","\n","# print(train_vectors)      # transform 된 결과 확인\n","\n","\n","##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 한 것 확인하는 방법 구현)\n","sample_num = -1                            # 확인하고 싶은 샘플 번호\n","sample_origin = train_data[sample_num]    # 확인하고 싶은 샘플의 원래 문장\n","sample_transform = train_vectors[sample_num]    # 확인하고 싶은 샘플의 transform된 결과\n","sample_inverse_transform = vectorizer.inverse_transform(sample_transform) # 확인하고 싶은 샘플의 transform된 결과를 다시 단어의 조합으로 바꾼 결과\n","print(\"Original Input:{}\\nTransformed: {}\\nInv-transformed: {}\".format(sample_origin, sample_transform, sample_inverse_transform))    # 출력"],"metadata":{"id":"uVsAWEB2Cd2n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 훈련세트에서 훈련하고 평가하기\n","from sklearn.svm import LinearSVC     #Linear kernel SVM을 사용하기 위한 클래스     \n","\n","svm = LinearSVC()     # 모델 정의\n","svm.fit(train_vectors, train_data['label'])     # 모델 학습\n","\n","print(svm.coef_)      # weights (w)\n","print(svm.intercept_)     # bias (b)"],"metadata":{"id":"u_hMc3yACbYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 교차 검증을 사용한 평가\n","# from sklearn.model_selection import cross_val_score\n","\n","# all_data = train_data['text']+dev_data['text']+test_data['text']      # all_data = train_data + dev_data + test_data\n","# all_label = train_data['label']+dev_data['label']+test_data['label']  # all_label은 train_data, dev_data, test_date의 레이블을 모두 합한 것 \n","# all_vectors = vectorizer.transform(all_data)    # all_data를 숫자로 변환\n","# scores = cross_val_score(svm, all_vectors, all_label, cv=5)  # 5-cross validation\n","\n","# print(\"All scores:\", scores)  # 전체 점수 출력\n","# print(\"Average: {:.2f}%\".format(scores.mean()*100)) # 다섯 번의 스코어 평균 출력\n","# print(\"Standard deviation: {:.6f}\".format(scores.std()))  # 표준편차 출력 "],"metadata":{"id":"Np-m5f9DCT1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 그리드 탐색\n","# from sklearn.model_selection import GridSearchCV    \n","\n","# param_grid = [{'max_iter':[500, 1000, 5000], 'C': [1, 10, 100]}]        # 학습 max_iter와 C를 변동 하이퍼파라미터로 설정\n","# grid_search = GridSearchCV(svm, param_grid, cv=3)     # 하이퍼파라미터 서치 할 모델 설정, 각 모델별로 5-cross validation 실행\n","# grid_search.fit(train_vectors, train_data['label'])   # transformed train data로 학습\n","\n","# print(grid_search.cv_results_['mean_test_score'])     # 파라미터 서치 결과\n","# print(grid_search.best_params_)   #최고의 모델 파라미터 \n","\n","# #파라미터 서치 결과 출력\n","# for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n","#   print(mean_score, params)       "],"metadata":{"id":"DtH3CLrnCUhy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 테스트 세트로 시스템 평가하기\n","from sklearn.metrics import accuracy_score    # Accuracy 측정 함수 import\n","\n","final_model = svm #grid_search.best_estimator_     # grid search에 의해 정해진 제일 좋은 하이퍼파라미터\n","\n","pred_results = final_model.predict(test_vectors)    # 최종 모델로 test 데이터 예측\n","accuracy = accuracy_score(test_data['label'], pred_results)   # 정확도 측정\n","\n","print(\"Accuracy: {:.2f}%\".format(accuracy*100))   # 정확도 출력 "],"metadata":{"id":"caRvzXUtCUrv"},"execution_count":null,"outputs":[]}]}