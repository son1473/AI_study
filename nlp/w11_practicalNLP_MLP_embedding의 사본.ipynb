{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GHnDE3OC6lrl"},"outputs":[],"source":["##### 데이터 다운로드\n","!pip install datasets   # Package install\n","\n","from datasets import load_dataset   # Huggingface 데이터셋 패키지 import\n","data = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAO2bWH5ZCzS"},"outputs":[],"source":["##### 코드 상단에서 KoNLPy, Mecab 설치 명령어 실행\n","# connect google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Download konlpy\n","%cd ./drive/MyDrive/Colab\\ Notebooks/\n","! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n","%cd ./Mecab-ko-for-Google-Colab\n","!bash install_mecab-ko_on_colab_light_220429.sh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o2TRw3m1ZIDA"},"outputs":[],"source":["##### Mecab 동작 확인코드 실행\n","# from konlpy.tag import Mecab  # KoNLPy를 통해 Mecab 패키지 import\n","# mecab = Mecab()\n","\n","# sentence = \"실용자연어처리 실습 진행중 이에요. 수업을 시작 할게요\"\n","# print(mecab.morphs(sentence)) # 형태소 출력\n","# print(mecab.nouns(sentence))  # 명사 출력\n","# print(mecab.pos(sentence))    # 형태소와 형태소 태그 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5qNkqVzPGvg"},"outputs":[],"source":["##### Word embedding 확인\n","import gensim\n","import numpy as np\n","\n","# load word2vec embedding\n","embedding_model = gensim.models.Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/word2vec/word2vec')\n","# 얘가 좀 대단한 거 같은데, 얘가 룩업테이블 만드는 거 같은데"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_NM2aMmCjkA","executionInfo":{"status":"ok","timestamp":1685364274373,"user_tz":-540,"elapsed":23,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"f3669453-e7a7-465d-c4b8-8ed2a1a595e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'label': 1, 'text': '역시 명작 어렸을때 봤을때도 재밌었고 지금 봐도 몇억배 이상으로 재밌어요'}\n"]}],"source":["##### 데이터 구조 훑어보기\n","# print(\"Data type: \", type(data))    # 데이터 타입 확인\n","# print(\"Data structure: \", data)     # 데이터 구조 확인\n","# print(\"Data keys: \", data.keys())   # 데이터 키 확인\n","\n","print(data['train'][0])   # 실제 데이터 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35,"referenced_widgets":["5d7482fbe0a64fcbb5cd4cdd5ce624dd","948e0f5f76374e55b9798a3021ba176c","bbf97798b7854eec8ccf7ba8d2c56bf6","cc06aa44b5d840d99b9bf5d85b5159ec","cae5a3d7ab004a23bc967034a470089a","016a6b2eb76946d7b3462b7d9a97cc34","b7c07c0194804e8ebce07cc9f34a8f23","a007c88feec0410482816aa2236b65ed","9c825a154fff415595a5092cf1c33635","8c79530353fd49a1b7e5b7dcf27700a3","7d66210defc94ec9ae3e49bb19acd9b6","72b2a4e26e42407bb17652b8a2dd1c26","99768e9c71bc4ec0a33f7e7ee0d7f293","4c2f9e9bf04a4145ad9982ea7920ac51","3150cc5d92e84ad6a3c7793e4b49450a","b46082e4f303471b935cfaa6ae434719","eadead22538c4999ac5360c711f7bc0c","3095ef104c7b47c8b4f072c4a8bd7f68","0a039040fcf2407f8cdd36ff8faa40ee","84516022bfd942b5b358e1b7dc64802c","8f1d27b381584cebbc2c7e97ff01368d","311e3727dd914dc4a098a39516c260f9","0d5daa361c2d40158e25366bdfabc49c","d6169007e7c348509a0d37b3191a35dd","48b8d985d0ef4b46b014ce78fb604bfb","6c86cbd5b2f1471cb4932c9a07a74afe","93d045e75f8e4cb2a5cb908436c3f9d3","a37df8b8fd33416bb29f3d5f4f52911c","5853c4cf1ed24e298ae9228edadc56a8","e7f0155b37474c1487b625134e208f31","b01ca5042f964b61b60f02fcff5f7e30","5e633decd15a4a54953216836e6f1672","44e468280e534a48ba1d01a51f64d548"]},"id":"IqbCh4yMCiEv","executionInfo":{"status":"ok","timestamp":1685364282966,"user_tz":-540,"elapsed":8614,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"2de62098-fef3-4222-f71a-ead36867fe29"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/36000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7482fbe0a64fcbb5cd4cdd5ce624dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1333 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b2a4e26e42407bb17652b8a2dd1c26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2667 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d5daa361c2d40158e25366bdfabc49c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'label': 1, 'text': '역시 명작 어렸 을 때 봤 을 때 도 재밌 었 고 지금 봐도 몇 억 배 이상 으로 재밌 어요'}\n"]}],"source":["##### 테스트 세트 만들기\n","train_data = data['train']\n","dev_data = data['validation']\n","test_data = data['test']\n","\n","#print(train_data)\n","#print(dev_data)\n","#print(test_data)\n","\n","# mecab 형태소 분석기 사용\n","from konlpy.tag import Mecab  # KoNLPy를 통해 Mecab 패키지 import\n","mecab = Mecab()\n","\n","# 형태소 단위로 Tokenization 된 텍스트를 {train/dev/test}_data에 저장\n","train_data = train_data.map(lambda example: {'label': example['label'], 'text': ' '.join(mecab.morphs(example['text']))})\n","dev_data = dev_data.map(lambda example: {'label': example['label'], 'text': ' '.join(mecab.morphs(example['text']))})\n","test_data = test_data.map(lambda example: {'label': example['label'], 'text': ' '.join(mecab.morphs(example['text']))})\n","\n","print(train_data[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"u_hMc3yACbYS","executionInfo":{"status":"error","timestamp":1685364293600,"user_tz":-540,"elapsed":10637,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"896412d0-6855-4582-a961-4b183eb9c800"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-0c0ee31a6ff0>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# 임베딩 벡터를 텐서 자료형으로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0memb_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}],"source":["##### 훈련세트에서 훈련하고 평가하기\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","### 룩업테이블을 정의한다.\n","# load한 embedding 관련 변수\n","emb_words = embedding_model.wv.index_to_key # 사전 학습 된 워드 임베딩 단어들 #word2vec에 있는 단어들 가져오는 것\n","emb_vectors = embedding_model.wv.vectors # 사전 학습 된 워드 임베딩 벡터들 # 그 단어들의 벡터들을 가져 오는 것\n","emb_dim = embedding_model.vector_size # 사전 학습 된 워드 임베딩 사이즈 (N or D) #벡터들의 사이즈를 가져오는 것\n","emb_stoi = {} # 단어를 key로, 인덱스를 value로 갖는 dictionary # string to index를 줄여서 stoi라고 한다.\n","max_seq_len = 200 # 최대 길이: 직접 지정하는 고정 값 # 룩업테이블을 볼 때 얼마나 볼지를 정하는 거 같다.\n","\n","# pad 인덱스: 0 / unk 인덱스 : 1 설정\n","emb_stoi['<pad>'] = 0\n","emb_stoi['<unk>'] = 1\n","\n","# <pad> 단어와 <unk> 단어에 0으로 이루어진 벡터 부여\n","emb_vectors = np.concatenate((np.zeros(shape=(2, emb_dim)), emb_vectors), axis=0)\n","# dim == dimension 차원을 말한다.\n","\n","# 사전 학습 된 워드 임베딩에 등록되어있는 단어에 인덱스 부여\n","for i, word in enumerate(emb_words):\n","  emb_stoi[word] = i + 2\n","\n","# 임베딩 벡터를 텐서 자료형으로 변환\n","emb_vectors = torch.cuda.FloatTensor(emb_vectors)\n","\n","\n","def text_to_index(input_data, stoi, max_seq_len):\n","  all_index = []\n","\n","  for sample in input_data:\n","    index_list = []\n","    for word in sample['text'].split():\n","      if word in stoi.keys():  # 단어가 lookup table에 검색 가능한 경우\n","        index_list.append(stoi[word])\n","      else:  # 단어가 lookup table에 검색 불가능한 경우\n","        index_list.append(stoi['<unk>'])\n","\n","    # Padding: 샘플의 길이가 고정 크기의 최대 길이 (L)보다 작은 경우,pad 인덱스를 추가\n","    if max_seq_len > len(index_list):\n","      index_list = index_list + [stoi['<pad>']] * (max_seq_len - len(index_list))\n","    else: # 샘플의 길이가 고정 크기의 최대 길이 (L)보다 큰 경우 고정 크기까지만 처리\n","      index_list = index_list[:max_seq_len]\n","    all_index.append(index_list)\n","\n","  return all_index\n","\n","# train, dev, test data들을 index로 변환\n","train_index = text_to_index(train_data, emb_stoi, max_seq_len)\n","dev_index = text_to_index(dev_data, emb_stoi, max_seq_len)\n","test_index = text_to_index(test_data, emb_stoi, max_seq_len)\n","# print(train_index[0]) #테스트 해보았음\n","# print(train_index[100])\n","\n","\n","# randomness 제거\n","seed = 0\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","\n","\n","# MLP 모델의 아키텍쳐(구조) 정의\n","class MLP(nn.Module):\n","  def __init__(self, input_size, hidden_size, output_size, max_seq_len):\n","    super(MLP, self).__init__()\n","    # 임베딩 계층\n","    self.word_embedding = nn.Embedding.from_pretrained(embeddings=emb_vectors) #\n","    # 각 층에 대한 정의\n","    self.input_size = input_size\n","    self.max_seq_len = max_seq_len\n","    self.layer1 = nn.Linear(max_seq_len * input_size, hidden_size) # nn.Linear(input_size, hidden_size)\n","    self.layer2 = nn.Linear(hidden_size, int(0.5*hidden_size))\n","    # self.layer3 = nn.Linear(int(0.5*hidden_size), output_size)\n","    self.layer3 = nn.Linear(int(0.5*hidden_size), int(2*hidden_size))\n","    self.layer4 = nn.Linear(int(2*hidden_size), hidden_size)\n","    self.layer5 = nn.Linear(hidden_size, output_size)\n","\n","    # 활성화 함수\n","    self.gelu = nn.GELU()\n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    # 실제(입력) 데이터: x\n","    # x를 가지고 순전파를 진행\n","    # print(\"출력\", x)\n","    word_emb = self.word_embedding(torch.cuda.LongTensor(x))\n","    word_emb_new = word_emb.view((-1, self.max_seq_len * self.input_size))\n","    print(word_emb.shape)\n","    out1 = self.layer1(word_emb_new)\n","    # out1 = self.layer1(x) #(sum)\n","    out2 = self.gelu(out1) # hidden_size\n","    out3 = self.layer2(out2)\n","    out4 = self.gelu(out3)\n","    out5 = self.layer3(out4)\n","    out6 = self.gelu(out5)\n","    out7 = self.layer4(out6)\n","    out8 = self.gelu(out7)\n","    out9 = self.layer5(out8)\n","    out10 = self.softmax(out9)\n","    return out10\n","    # out5 = self.layer3(out4)\n","    # out6 = self.softmax(out5)\n","\n","    # return out6\n","\n","'''\n","\n","단어 1개 -> 100차원\n","[  |   |  |  | 역시 |   |  |  ] 100차원\n","[  |   |  |  |    |  명작  |  |  ] 100차원\n","최대 길이 -> 각 세로 길이가 30 (100 * 30차원인가)\n","배치 -> 128개\n","텐서는 이렇게 표현 => [128, 30, 100]\n","[3, 2, 5] => 개수, 세로, 가로 이기때문에\n","\n","\n","class MLP(nn.Module):\n","  def __init__(self, input_size, hidden_size, output_size):\n","    super(MLP, self).__init__()\n","    self.layer1 = nn.Linear(input_size, hidden_size)\n","    self.layer2 = nn.Linear(hidden_size, int(0.5*hidden_size))\n","    self.layer3 = nn.Linear(int(0.5*hidden_size), int(2*hidden_size))\n","    self.layer4 = nn.Linear(int(2*hidden_size), hidden_size)\n","    self.layer5 = nn.Linear(hidden_size, output_size)\n","    self.gelu = nn.GELU()\n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    out1 = self.layer1(x)\n","    out2 = self.gelu(out1)\n","    out3 = self.layer2(out2)\n","    out4 = self.gelu(out3)\n","    out5 = self.layer3(out4)\n","    out6 = self.gelu(out5)\n","    out7 = self.layer4(out6)\n","    out8 = self.gelu(out7)\n","    out9 = self.layer5(out8)\n","    out10 = self.softmax(out9)\n","\n","    return out10\n","'''\n","# 하이퍼파라미터 셋팅\n","input_size = emb_dim # len(vectorizer.vocabulary_) # input size\n","hidden_size = 100 # hidden size\n","output_size = 2 # output size is 2 (positive/negative)\n","learning_rate = 0.00002\n","batch_size = 128\n","num_epochs = 30\n","\n","# 모델 초기화\n","model = MLP(input_size, hidden_size, output_size, max_seq_len)\n","device = torch.device(\"cuda\") # use GPU\n","model = model.to(device)\n","\n","# optimizer, loss function 정의\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","loss_function = nn.CrossEntropyLoss()\n","\n","# dev_vectors와 dev_data['label']을 텐서 자료형으로 변환\n","dev_tensors = dev_index # torch.cuda.FloatTensor(dev_vectors.toarray(), device=device) # 강의자료 11에서 변경\n","dev_labels = torch.tensor(dev_data['label'], dtype=torch.long, device=device)\n","\n","# 학습 시작 (총 num_epochs 만큼)\n","for epoch in range(num_epochs):\n","  # model을 학습모드로 만든다.\n","  model.train()\n","\n","  # 학습을 하면서 보고싶은 숫자 (학습이 잘되는지 확인)\n","  epoch_loss = 0\n","  best_accuracy = 0\n","\n","  # train_vectors를 텐서 자료형으로 변환\n","  train_tensors = train_index # torch.cuda.FloatTensor(train_vectors.toarray(), device=device)\n","\n","  # batch size 단위로 학습 진행\n","  for i in range(0, len(train_tensors), batch_size):\n","\n","    # batch 단위 데이터 생성\n","    batch_data = train_tensors[i:i+batch_size] # batch size 크기의 데이터가 batch_data\n","    batch_labels = torch.tensor(train_data['label'][i:i+batch_size], device=device)\n","\n","    # 1. 순전파\n","    outputs = model(batch_data)\n","    # 2. 오차 계산\n","    loss = loss_function(outputs, batch_labels)\n","    # 3. 역전파\n","    optimizer.zero_grad()\n","    # 4. 가중치 업데이트\n","    loss.backward()\n","    optimizer.step()\n","\n","    # epoch loss\n","    epoch_loss += loss.item()\n","\n","  # 매 epoch마다 dev 성능 측정\n","  # 모델을 평가하는 모드로 셋팅\n","  model.eval()\n","  with torch.no_grad():\n","    dev_outputs = model(dev_tensors) # dev 데이터의 순전파\n","    dev_preds = torch.argmax(dev_outputs, axis=1)\n","    dev_accuracy = torch.sum(dev_preds == dev_labels).item() / len(dev_labels)\n","\n","    # save best model on dev data\n","    if dev_accuracy > best_accuracy:\n","      best_model = model\n","      best_accuracy = dev_accuracy\n","\n","  print(f\"Epoch {epoch+1}, Accuracy: {dev_accuracy} , loss: {epoch_loss/len(train_tensors)}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"F8hrEr8EHUs7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Np-m5f9DCT1u"},"outputs":[],"source":["##### 교차 검증을 사용한 평가\n","# from sklearn.model_selection import cross_val_score\n","\n","# all_data = train_data['text']+dev_data['text']+test_data['text']      # all_data = train_data + dev_data + test_data\n","# all_label = train_data['label']+dev_data['label']+test_data['label']  # all_label은 train_data, dev_data, test_date의 레이블을 모두 합한 것\n","# all_vectors = vectorizer.transform(all_data)    # all_data를 숫자로 변환\n","# scores = cross_val_score(svm, all_vectors, all_label, cv=5)  # 5-cross validation\n","\n","# print(\"All scores:\", scores)  # 전체 점수 출력\n","# print(\"Average: {:.2f}%\".format(scores.mean()*100)) # 다섯 번의 스코어 평균 출력\n","# print(\"Standard deviation: {:.6f}\".format(scores.std()))  # 표준편차 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DtH3CLrnCUhy"},"outputs":[],"source":["##### 그리드 탐색\n","# from sklearn.model_selection import GridSearchCV\n","\n","# param_grid = [{'max_iter':[500, 1000, 5000], 'C': [1, 10, 100]}]        # 학습 max_iter와 C를 변동 하이퍼파라미터로 설정\n","# grid_search = GridSearchCV(svm, param_grid, cv=3)     # 하이퍼파라미터 서치 할 모델 설정, 각 모델별로 5-cross validation 실행\n","# grid_search.fit(train_vectors, train_data['label'])   # transformed train data로 학습\n","\n","# print(grid_search.cv_results_['mean_test_score'])     # 파라미터 서치 결과\n","# print(grid_search.best_params_)   #최고의 모델 파라미터\n","\n","# #파라미터 서치 결과 출력\n","# for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n","#   print(mean_score, params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"caRvzXUtCUrv"},"outputs":[],"source":["##### 테스트 세트로 시스템 평가하기\n","from sklearn.metrics import accuracy_score # Accuracy 측정 함수 import\n","final_model = best_model # MLP 모델\n","test_tensors = test_index # torch.cuda.FloatTensor(test_vectors.toarray(), device=device)\n","test_outputs = final_model(test_tensors) # 최종 모델로 test 데이터 예측\n","pred_results = torch.argmax(test_outputs, axis=1)\n","accuracy = accuracy_score(test_data['label'], pred_results.tolist()) # 정확도 측정\n","print(\"Accuracy: {:.2f}%\".format(accuracy*100)) # 정확도 출력"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1dTrGRHcIrjnJ54okbtr-EF-AQpJJEj1u","timestamp":1685364467444}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5d7482fbe0a64fcbb5cd4cdd5ce624dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_948e0f5f76374e55b9798a3021ba176c","IPY_MODEL_bbf97798b7854eec8ccf7ba8d2c56bf6","IPY_MODEL_cc06aa44b5d840d99b9bf5d85b5159ec"],"layout":"IPY_MODEL_cae5a3d7ab004a23bc967034a470089a"}},"948e0f5f76374e55b9798a3021ba176c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_016a6b2eb76946d7b3462b7d9a97cc34","placeholder":"​","style":"IPY_MODEL_b7c07c0194804e8ebce07cc9f34a8f23","value":"Map:  99%"}},"bbf97798b7854eec8ccf7ba8d2c56bf6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a007c88feec0410482816aa2236b65ed","max":36000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c825a154fff415595a5092cf1c33635","value":36000}},"cc06aa44b5d840d99b9bf5d85b5159ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c79530353fd49a1b7e5b7dcf27700a3","placeholder":"​","style":"IPY_MODEL_7d66210defc94ec9ae3e49bb19acd9b6","value":" 35819/36000 [00:06&lt;00:00, 4241.20 examples/s]"}},"cae5a3d7ab004a23bc967034a470089a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"016a6b2eb76946d7b3462b7d9a97cc34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7c07c0194804e8ebce07cc9f34a8f23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a007c88feec0410482816aa2236b65ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c825a154fff415595a5092cf1c33635":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c79530353fd49a1b7e5b7dcf27700a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d66210defc94ec9ae3e49bb19acd9b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72b2a4e26e42407bb17652b8a2dd1c26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99768e9c71bc4ec0a33f7e7ee0d7f293","IPY_MODEL_4c2f9e9bf04a4145ad9982ea7920ac51","IPY_MODEL_3150cc5d92e84ad6a3c7793e4b49450a"],"layout":"IPY_MODEL_b46082e4f303471b935cfaa6ae434719"}},"99768e9c71bc4ec0a33f7e7ee0d7f293":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eadead22538c4999ac5360c711f7bc0c","placeholder":"​","style":"IPY_MODEL_3095ef104c7b47c8b4f072c4a8bd7f68","value":"Map:  88%"}},"4c2f9e9bf04a4145ad9982ea7920ac51":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a039040fcf2407f8cdd36ff8faa40ee","max":1333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84516022bfd942b5b358e1b7dc64802c","value":1333}},"3150cc5d92e84ad6a3c7793e4b49450a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f1d27b381584cebbc2c7e97ff01368d","placeholder":"​","style":"IPY_MODEL_311e3727dd914dc4a098a39516c260f9","value":" 1170/1333 [00:00&lt;00:00, 2402.00 examples/s]"}},"b46082e4f303471b935cfaa6ae434719":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"eadead22538c4999ac5360c711f7bc0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3095ef104c7b47c8b4f072c4a8bd7f68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a039040fcf2407f8cdd36ff8faa40ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84516022bfd942b5b358e1b7dc64802c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f1d27b381584cebbc2c7e97ff01368d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"311e3727dd914dc4a098a39516c260f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d5daa361c2d40158e25366bdfabc49c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6169007e7c348509a0d37b3191a35dd","IPY_MODEL_48b8d985d0ef4b46b014ce78fb604bfb","IPY_MODEL_6c86cbd5b2f1471cb4932c9a07a74afe"],"layout":"IPY_MODEL_93d045e75f8e4cb2a5cb908436c3f9d3"}},"d6169007e7c348509a0d37b3191a35dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a37df8b8fd33416bb29f3d5f4f52911c","placeholder":"​","style":"IPY_MODEL_5853c4cf1ed24e298ae9228edadc56a8","value":"Map:  94%"}},"48b8d985d0ef4b46b014ce78fb604bfb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7f0155b37474c1487b625134e208f31","max":2667,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b01ca5042f964b61b60f02fcff5f7e30","value":2667}},"6c86cbd5b2f1471cb4932c9a07a74afe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e633decd15a4a54953216836e6f1672","placeholder":"​","style":"IPY_MODEL_44e468280e534a48ba1d01a51f64d548","value":" 2495/2667 [00:01&lt;00:00, 2651.65 examples/s]"}},"93d045e75f8e4cb2a5cb908436c3f9d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"a37df8b8fd33416bb29f3d5f4f52911c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5853c4cf1ed24e298ae9228edadc56a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7f0155b37474c1487b625134e208f31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b01ca5042f964b61b60f02fcff5f7e30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e633decd15a4a54953216836e6f1672":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44e468280e534a48ba1d01a51f64d548":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
