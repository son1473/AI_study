{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zAyy1GO5GzJk"},"outputs":[],"source":["3# install huggingface datasets and pytorch-crf\n","! pip install datasets\n","! pip install pytorch-crf"]},{"cell_type":"code","source":["# Drive mount\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# import pytorch, numpy libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","# import huggingface's datasets libraries\n","from datasets import load_dataset\n","\n","# import Vectors from torchtext libraries\n","from torchtext.vocab import Vectors\n","\n","# import copy libraries for deepcopy\n","import copy\n","\n","# import pytorch crf\n","from torchcrf import CRF"],"metadata":{"id":"rU1skCgpG3Eq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 개체명 인식 데이터(conll2003) 로드 및 데이터 구조 훑어보기\n","data = load_dataset(\"conll2003\")\n","\n","print(\"Data type: \", type(data))    # 데이터 타입 확인\n","print(\"Data structure: \", data)     # 데이터 구조 확인\n","print(\"Data keys: \", data.keys())   # 데이터 키 확인\n","\n","print(\"Data 0: \", data['train'][0])   # 실제 데이터 확인\n","# id :0 token들이 들어있고, pos tags 에는 숫자가 리스트로 들어잇고 chunk_tags에도 숫자들이 들어있다.  num 태그를 예측하는 게 오늘 모델이 해야 하는 일이다.\n","# 각 토큰이 어떤 구 구조를 가지고 있는지를 chunk 태그에 속해져 있다\n","#  구 구조를 예측하는 문제로 바꿀 수도 있다.\n","# 구문 구조를 분석할 수 있는\n","# 구문 구조를 사용해서\n","# MISC는 기타 등등을 의미한다. GERMAN은 LOC이기도 하지만, 국가 조직명 이기도 해서 여러 태그에 속하면 MISC에 속하게 되어 있다\n","# 카테고리가 몇 개있는지 추축할 숭 ㅣㅆ다. 2* 4 +1 로 해서 9가 나오기 때문에 4개로 알 수 있다.\n","\n","\n","print(\"Data class label: \", data['train'].features['ner_tags'].feature)    # 데이터 레이블 확인\n","# 데이터 레이블 확인하니 0번에 B-PER 감탄사구\n","num_labels = data['train'].features['ner_tags'].feature.num_classes   # num_labels 변수에 처리할 레이블 개수 저장\n","print(num_labels)"],"metadata":{"id":"8PuB7HpdHDcX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##### 데이터 세트 만들기\n","train_data = data['train']\n","print()\n","dev_data = data['validation']\n","test_data = data['test']\n","\n","# 데이터에서 가장 긴 길이를 maximum sequence length로 지정 - 113개가 나온다.\n","# 패딩을 113까지 하겠다라는 의미가 된다. 전체 데이터 셋에서 가장 큰 걸로 정한다.\n","# 너무 길게 잡으면 패딩의 영향이 커지고\n","# 너무 작게 잡으면 데이터가 작아진다.\n","\n","max_seq_len =  max([len(sample['tokens']) for sample in train_data])\n","print(\"max_seq_len: \", max_seq_len)\n","\n","# 레이블 인덱스를 문자열 레이블로 바꾸는 딕셔너리 선언 (Ex: 3 --> B-ORG / 0 --> O / 1 --> B-PER)\n","# 3을 넣으면 B-ORG 가 나오도록 이러한 매핑을 만들었다\n","# O 라는태그를 많이 가지기 때문에 , 인덱스를 태그로 바꿔야 성능을 측정할 수 있다.\n","\n","# 레이블 인덱스를 STRING으로\n","label_itos = {}\n","for i in range(num_labels):\n","  label_itos[i] = data['train'].features['ner_tags'].feature.int2str(i)\n","print(label_itos)"],"metadata":{"id":"tMRDITEsHLh_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686981201297,"user_tz":-540,"elapsed":2859,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"4c55300c-292c-400b-d547-c424c84a2eda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","max_seq_len:  113\n","{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'}\n"]}]},{"cell_type":"code","source":["### 사전학습 된 Glove 임베딩 불러오기\n","embedding_model = Vectors(cache=\"/content/drive/MyDrive/Colab Notebooks/glove/\", name=\"glove.6B.300d.txt\")\n","\n","# 앞으로 사용할 임베딩 정보 변수에 저장해놓기\n","# 임베딩 단어들을 숫자로 변환\n","emb_words = copy.deepcopy(list(embedding_model.stoi))\n","emb_vectors_origin = copy.deepcopy(embedding_model.vectors)\n","emb_dim = embedding_model.dim\n","emb_stoi = {}\n","\n","# 임베딩 정보 출력\n","print(\"Is <pad> token in words?: \", \"<pad>\" in emb_words)  # 임베딩에 pad token이 있는지 확인 패드 토큰이 없더라, 나중에 추가해줘야겠다는 사실을 알 숭 ㅣㅆ다.\n","print(\"Is <unk> token in words?: \",\"<unk>\" in emb_words)  # 임베딩에 unk token이 있는지 확인\n","print(\"emb_words(0~10): \", emb_words[0:10])     # 임베딩 단어의 0번부터 10번 단어 출력\n","print(\"emb_dim: \", emb_dim)   # 임베딩 dimension 확인 - 300 차원이다."],"metadata":{"id":"m3cD5PZHG8HH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686981206319,"user_tz":-540,"elapsed":5025,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"cac3a033-8d8b-4996-8ed9-50911f0eea24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Is <pad> token in words?:  False\n","Is <unk> token in words?:  False\n","emb_words(0~10):  ['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]\n","emb_dim:  300\n"]}]},{"cell_type":"code","source":["# 임베딩에 룩업테이블 만ㄷ을 건데 pad랑 unk를 먼저 넣는다.\n","# 병렬 처리를 하기 위해 pad 처리를 해야 한다.\n","### 룩업테이블 정의\n","# pad 토큰, unk 토큰 추가: <pad> -> 0, <unk> -> 1\n","emb_stoi['<pad>'] = 0\n","emb_stoi['<unk>'] = 1\n","\n","print(len(emb_vectors_origin))    # Glove 임베딩에서 불러온 원래 임베딩에 포함된 단어 수 출력\n","pad_vector = torch.zeros(1, emb_dim)\n","unk_vector = torch.zeros(1, emb_dim)\n","emb_vectors = torch.cat((pad_vector, unk_vector, emb_vectors_origin), axis=0)\n","print(len(emb_vectors))   # Glove 임베딩에서 불러온 원래 임베딩에 포함된 단어 수 + pad 토큰, unk 토큰 더한 개수 출력\n","# 2개 더해서 400002개 나온다.\n","\n","# emb_stoi: 단어가 key, 단어의 index가 value인 dictionary 생성\n","for i, word in enumerate(emb_words):\n","  emb_stoi[word] = i + 2"],"metadata":{"id":"lz3MdTdjJFPg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686981206822,"user_tz":-540,"elapsed":518,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"632fd8a0-4648-4166-c499-058b62db3487"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["400000\n","400002\n"]}]},{"cell_type":"code","source":["### 인덱스 변환\n","def text_to_index(input_data, stoi, max_seq_len):\n","  all_index = []\n","\n","  for sample in input_data:\n","    index_list = []\n","    for word in sample['tokens']:\n","      word = word.lower()\n","      if word in stoi.keys(): # 단어가 lookup table에 검색 가능한 경우\n","        index_list.append(stoi[word])\n","      else: # 단어가 lookup table에 검색 불가능한 경우\n","        index_list.append(stoi['<unk>'])\n","\n","    # Padding: 샘플의 길이가 고정 크기의 최대 길이 (L)보다 작은 경우, pad 인덱스를 추가\n","    if max_seq_len > len(index_list):\n","      index_list = index_list + [stoi['<pad>']] * (max_seq_len - len(index_list))\n","    else: # 샘플의 길이가 고정 크기의 최대 길이 (L)보다 큰 경우, 고정 크기까지만 처리\n","      index_list = index_list[:max_seq_len]\n","    all_index.append(index_list)\n","\n","  return all_index\n","\n","# train, dev, test data들을 index로 변환\n","train_index = text_to_index(train_data, emb_stoi, max_seq_len)\n","dev_index = text_to_index(dev_data, emb_stoi, max_seq_len)\n","test_index = text_to_index(test_data, emb_stoi, max_seq_len)\n","\n","# 패딩을 넣어서 길이가 같은 걸 알 수 있다\n","print(train_index[0])\n","print(train_index[-100])"],"metadata":{"id":"WRpfS3ZyT6pf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686981208657,"user_tz":-540,"elapsed":1838,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"04ebab25-d341-4144-f572-49961bb1bda5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[646, 7580, 516, 582, 6, 5262, 299, 10240, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[2512, 962, 616, 11880, 8841, 25, 7031, 4108, 26, 8, 9, 293, 18585, 1735, 552, 15, 187, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["# 단어는 한의 sequence가 있다.\n","# 입력하는 데이터 샘플마다 데이터\n","# 출력하는 것마다\n","# 문장 분류는 0 또는 1이었는데 이번에는 다른 분류 문제이기 때문에 레이블에 padding처리를 해야 한다.\n","### label에 padding을 적용\n","def pad_labels(original_data, max_seq_len, label_pad_index):\n","  padded_labels = []\n","\n","  for original_sample in original_data:\n","    original_label = original_sample['ner_tags']\n","    # Padding: 샘플의 레이블 길이가 고정 크기의 최대 길이 (L)보다 작은 경우, pad 인덱스를 추가\n","    if max_seq_len > len(original_label):\n","      new_label = original_label + [label_pad_index] * (max_seq_len - len(original_label))\n","    else: # 샘플의 레이블 길이가 고정 크기의 최대 길이 (L)보다 큰 경우, 고정 크기까지만 처리\n","      new_label = original_label[:max_seq_len]\n","    padded_labels.append(new_label)\n","\n","  return torch.tensor(padded_labels)\n","\n","# label 인덱스의 pad index는 전체 레이블 중 마지막 번호\n","label_pad_idx = num_labels\n","label_itos[label_pad_idx] = \"<PAD>\"\n","\n","# train, dev, test data의 레이블들을 pad index가 들어간 형태로 변환\n","train_labels = pad_labels(train_data, max_seq_len, label_pad_idx )\n","dev_labels = pad_labels(dev_data, max_seq_len, label_pad_idx )\n","test_labels = pad_labels(test_data, max_seq_len, label_pad_idx )\n","\n","# 레이블에 pad index가 잘 입력되었는지 출력 확인\n","print(train_labels[0])\n","print(train_labels[-100])"],"metadata":{"id":"xV5MezEGT7XE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686981212044,"user_tz":-540,"elapsed":3389,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"339f98da-b966-4c0c-ae83-3ecac4ad891c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3, 0, 7, 0, 0, 0, 7, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])\n","tensor([5, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n","        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])\n"]}]},{"cell_type":"code","source":["### NER 평가\n","def evaluate_iob(predictions, labels, itos):\n","  # 우리가 구해야할 것들 이 3가지\n","  true_positives = 0\n","  all_predictions = 0\n","  all_answers = 0\n","\n","  for preds, targets in zip(predictions, labels):\n","    # Get predicted named entities\n","    preds_string = [itos[int(index)] for index in preds]\n","    pred_entities = get_entities(preds_string)\n","\n","    # Get target(answer) named entities\n","    targets_string = [itos[int(index)] for index in targets]\n","    target_entities = get_entities(targets_string)\n","\n","    # Count all predictions and all targetst(answers)\n","    # 예측한 개수들\n","    all_predictions += len(pred_entities)\n","    all_answers += len(target_entities)\n","\n","    # Calculate true positives\n","    for entity in pred_entities:\n","      if entity in target_entities:\n","        true_positives += 1\n","        target_entities.remove(entity)\n","\n","  # Calculate precision, recall, and F1 score\n","  # 맞춘거 / 예측한 거\n","  # 예측 중에 모델이 몇개냐 맞췄나.\n","  precision = true_positives / (all_predictions + 1e-10) # 0나누기 에러가 나지 않기 위해서 정말 작은 값을 더해 준다.\n","  # 실제 예측 저\n","  recall = true_positives / (all_answers + 1e-10)\n","  # 산술 평균\n","  f1_score = 2 * (precision * recall) / (precision + recall + 1e-10)\n","\n","  return precision, recall, f1_score\n","\n","def get_entities(seq):\n","    \"\"\"Gets entities from sequence.\n","\n","    Args:\n","        seq (list): sequence of labels.\n","\n","    Returns:\n","        list: list of (chunk_type, chunk_start, chunk_end).\n","\n","    Example:\n","        >>> from seqeval.metrics.sequence_labeling import get_entities\n","        >>> seq = ['B-PER', 'I-PER', 'O', 'B-LOC']\n","        >>> get_entities(seq)\n","        [('PER', 0, 1), ('LOC', 3, 3)] # LOC는3번에서 시작해서 3번에서 끝난다.\n","        PER은 0번이랑 1번에 나온다.\n","    \"\"\"\n","    # for nested list\n","    if any(isinstance(s, list) for s in seq):\n","        seq = [item for sublist in seq for item in sublist + ['O']]\n","\n","    prev_tag = 'O'\n","    prev_type = ''\n","    begin_offset = 0\n","    chunks = []\n","    for i, chunk in enumerate(seq + ['O']):\n","        tag = chunk[0]\n","        type_ = chunk.split('-')[-1]\n","\n","        if end_of_chunk(prev_tag, tag, prev_type, type_):\n","            chunks.append((prev_type, begin_offset, i-1))\n","        if start_of_chunk(prev_tag, tag, prev_type, type_):\n","            begin_offset = i\n","        prev_tag = tag\n","        prev_type = type_\n","\n","    return chunks\n","\n","\n","def end_of_chunk(prev_tag, tag, prev_type, type_):\n","    \"\"\"Checks if a chunk ended between the previous and current word.\n","\n","    Args:\n","        prev_tag: previous chunk tag.\n","        tag: current chunk tag.\n","        prev_type: previous type.\n","        type_: current type.\n","\n","    Returns:\n","        chunk_end: boolean.\n","    \"\"\"\n","    chunk_end = False\n","\n","\n","    if prev_tag == 'B' and tag == 'B': chunk_end = True\n","    if prev_tag == 'B' and tag == 'O': chunk_end = True\n","    if prev_tag == 'I' and tag == 'B': chunk_end = True\n","    if prev_tag == 'I' and tag == 'O': chunk_end = True\n","\n","    if prev_tag != 'O' and prev_tag != '.' and prev_type != type_:\n","        chunk_end = True\n","\n","    return chunk_end\n","\n","\n","def start_of_chunk(prev_tag, tag, prev_type, type_):\n","    \"\"\"Checks if a chunk started between the previous and current word.\n","\n","    Args:\n","        prev_tag: previous chunk tag.\n","        tag: current chunk tag.\n","        prev_type: previous type.\n","        type_: current type.\n","\n","    Returns:\n","        chunk_start: boolean.\n","    \"\"\"\n","    chunk_start = False\n","\n","    if tag == 'B': chunk_start = True\n","\n","    if tag != 'O' and tag != '.' and prev_type != type_:\n","        chunk_start = True\n","\n","    return chunk_start"],"metadata":{"id":"WfRgPIGWm-D-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### NER 모델 만들기\n","class LSTMNER(torch.nn.Module):\n","  def __init__(self, input_size, hidden_size, output_size, word_vectors, pad_word_id, pad_label_id):\n","    super(LSTMNER, self).__init__()\n","    self.pad_word_id = pad_word_id # word embedding에서의 padding index\n","    self.pad_label_id = pad_label_id # label index에서의 padding index\n","    bidirectional=True\n","\n","    ### [Step 1] 레이어 선언 부분 구현\n","    # 1. 임베딩 레이어 선언\n","    self.word_embedding = nn.Embedding.from_pretrained(embeddings=word_vectors)\n","    # 2. BiLSTM 레이어 선언\n","    self.bilstm = nn.LSTM(input_size=emb_dim, hidden_size = hidden_size, bidirectional=True, batch_first=True) # 여기 뒤에 두개가 중요하다.\n","    # 3. 출력 Linear layer 선언\n","    self.linear = nn.Linear(2*hidden_size, output_size)\n","    # 4. 출력 CRF layer 선언\n","    # self.crf = CRF(output_size)\n","    self.crf = CRF(output_size, batch_first=True)\n","\n","  ### [Step 2] BiLSTM 순전파 부분 구현 # 이름을 이렇게 만든 거 뿐!\n","  def get_lstm_outputs(self, x):\n","    # 1. 입력 인덱스 시퀀스를 단어 임베딩으로 만들기\n","    embedded_sents = self.word_embedding(x)\n","    # 2. 임베딩 결과를 BiLSTM에 입력 & 3. BiLSTM 시퀀스에서의 출력값을 사용\n","    # 모든 은닉층들이 저장될 것이다. 문장을 받고 싶으면 뒤에거 시퀀스를 아고 싶으면 앞에거\n","    all_hidden_states, _ = self.bilstm(embedded_sents) # 튜플을 반환한다.\n","    # 4. hidden state를 풀고자 하는 문제(레이블 차원의 숫자)로 변환\n","\n","    outputs = self.linear(all_hidden_states)\n","    # 패딩이 들어가서 8에서 하나 더 들어가서 10개가 되었다.\n","    # 1(O) + 4(PER, loc, ORG, MISC ) *2(Bi directional) +1(padding)\n","\n","    # 5. padded label을 위한 후처리\n","    # 패드 마스크에\n","    # 입력 단어가 7개였나보다.\n","\n","    pad_mask = (x == self.pad_word_id)\n","    outputs[:, :, self.pad_label_id] += pad_mask * 10000\n","    return outputs\n","\n","  ### [Step 3] CRF layer 순전파 부분 구현\n","  def predict(self, x):\n","    # 1. BiLSTM 결과 값 구하기\n","    lstm_outputs = self.get_lstm_outputs(x)\n","    # 2. CRF layer의 알고리즘에 의한 최종 출력 결과 예측\n","    predicted_res = self.crf.decode(lstm_outputs)\n","    return predicted_res\n","\n","  ### [Step 4] CRF loss 계산 구현\n","  def get_crf_loss(self, outputs, labels):\n","    # 1. pytorch-crf를 사용한 crf loss 계산\n","    loss = self.crf(outputs, labels)\n","    return -loss\n"],"metadata":{"id":"ZNGpJGglVcEQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# randomness 제거\n","seed = 0\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","\n","# 하이퍼파라미터 셋팅\n","input_size = emb_dim # To do\n","hidden_size = 100 # hidden size\n","output_size =  num_labels + 1 # To do\n","learning_rate = 0.001\n","batch_size = 128\n","num_epochs = 30\n","\n","# BiLSTM NER 모델 초기화\n","model = LSTMNER(input_size, hidden_size, output_size, emb_vectors, emb_stoi['<pad>'], label_pad_idx)\n","device = torch.device(\"cuda\") # use GPU\n","model = model.to(device)\n","\n","# optimizer 정의\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# dev_index를 dev_tensors로 사용\n","dev_tensors = torch.cuda.LongTensor(dev_index)\n","\n","# best f1 score 초기값 셋팅\n","best_f1 = 0\n","\n","# 학습 시작 (총 num_epochs 만큼)\n","for epoch in range(num_epochs):\n","  # model을 학습모드로 만든다.\n","  model.train()\n","  epoch_loss = 0\n","\n","  # train_index를 train_tensors로 사용\n","  train_tensors = torch.cuda.LongTensor(train_index)\n","\n","  # batch size 단위로 학습 진행\n","  for i in range(0, len(train_tensors), batch_size):\n","\n","    # batch 단위 데이터 생성\n","    batch_data = train_tensors[i:i+batch_size] # batch size 크기의 데이터가 batch_data\n","    batch_labels = torch.Tensor(train_labels[i:i+batch_size]).to(device)\n","\n","    # 1. Bi-LSTM 순전파\n","    # 배치 데이터를 구ㅎ\n","    outputs = model.get_lstm_outputs(batch_data)\n","    # 2. CRF 오차 계산\n","    loss = model.get_crf_loss(outputs, batch_labels)\n","    # 3. 역전파\n","    optimizer.zero_grad()\n","    # 4. 가중치 업데이트\n","    loss.backward()\n","    optimizer.step()\n","\n","    # epoch loss\n","    epoch_loss = loss.item()\n","\n","  # 매 epoch마다 dev 성능 측정\n","  # 모델을 평가하는 모드로 셋팅\n","  model.eval()\n","  with torch.no_grad():\n","    dev_preds = model.predict(dev_tensors) # dev 데이터의 BiLSTM-CRF 결과 출력\n","    dev_p, dev_r, dev_f1 = evaluate_iob(dev_preds, dev_labels, label_itos)\n","\n","    # save best model on dev data\n","    if dev_f1 > best_f1:\n","      best_model = model\n","      best_f1 = dev_f1\n","\n","    print(f\"Epoch {epoch+1}, F1-score: {dev_f1} , loss: {epoch_loss/len(train_tensors)}\")"],"metadata":{"id":"3hXnnyO8ZbO2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686981828887,"user_tz":-540,"elapsed":616849,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"f12112cb-28a5-4d63-c296-c79d43323dfc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:493.)\n","  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, F1-score: 0.6415917842905073 , loss: 0.034096574318068514\n","Epoch 2, F1-score: 0.7875141883723324 , loss: 0.015570472188590556\n","Epoch 3, F1-score: 0.8406558875122492 , loss: 0.009899579802008404\n","Epoch 4, F1-score: 0.8699556602744503 , loss: 0.007264439854711203\n","Epoch 5, F1-score: 0.8839072147244498 , loss: 0.006124919877501602\n","Epoch 6, F1-score: 0.8962117855060544 , loss: 0.005350402392991952\n","Epoch 7, F1-score: 0.9043305346384686 , loss: 0.004718324905633502\n","Epoch 8, F1-score: 0.9104633863624728 , loss: 0.004304358663912827\n","Epoch 9, F1-score: 0.9144993676302069 , loss: 0.0038903924221921514\n","Epoch 10, F1-score: 0.916881266729895 , loss: 0.0035609999287800013\n","Epoch 11, F1-score: 0.916452933101423 , loss: 0.0034007549319849013\n","Epoch 12, F1-score: 0.9170705145157401 , loss: 0.002875507442489851\n","Epoch 13, F1-score: 0.9206661206161112 , loss: 0.002541663699166726\n","Epoch 14, F1-score: 0.9232367413387282 , loss: 0.002341357453172851\n","Epoch 15, F1-score: 0.9218613774565289 , loss: 0.002319101203617976\n","Epoch 16, F1-score: 0.9217410180765505 , loss: 0.002225624955487501\n","Epoch 17, F1-score: 0.9219673552994835 , loss: 0.0020075137098497257\n","Epoch 18, F1-score: 0.9248913042978161 , loss: 0.0017493412150131756\n","Epoch 19, F1-score: 0.927179150190903 , loss: 0.0016202549675949007\n","Epoch 20, F1-score: 0.927400725942736 , loss: 0.0016514137169717257\n","Epoch 21, F1-score: 0.9272857378263661 , loss: 0.0015490349690193007\n","Epoch 22, F1-score: 0.9256790258989815 , loss: 0.0014154974716900507\n","Epoch 23, F1-score: 0.9264317180116713 , loss: 0.0012463499750730005\n","Epoch 24, F1-score: 0.9250771264374372 , loss: 0.0010504949789901005\n","Epoch 25, F1-score: 0.924739482775163 , loss: 0.0009125062317498754\n","Epoch 26, F1-score: 0.9260014325358156 , loss: 0.0007878712342425753\n","Epoch 27, F1-score: 0.9267917055767493 , loss: 0.0006721387365572252\n","Epoch 28, F1-score: 0.9252372332339601 , loss: 0.0006187237376255253\n","Epoch 29, F1-score: 0.9256134968825076 , loss: 0.0004985399900292002\n","Epoch 30, F1-score: 0.9249288684113617 , loss: 0.0004718324905633502\n"]}]},{"cell_type":"code","source":["##### 테스트 세트로 시스템 평가하기\n","final_model = best_model # 최고의 dev 성능을 가진 BiLSTM-CRF 모델\n","test_tensors = torch.cuda.LongTensor(test_index)\n","test_preds = model.predict(test_tensors) # 최종 모델로 test 데이터 예측\n","test_p, test_r, test_f1 = evaluate_iob(test_preds, test_labels, label_itos) # 정확도 측정\n","print(\"Test F1-score: {:.2f}%\".format(test_f1*100)) # 정확도 출력"],"metadata":{"id":"uaGNe-KgodXz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686981836774,"user_tz":-540,"elapsed":7904,"user":{"displayName":"‍손명근[재학 / ELLT학과]","userId":"11139733555195103952"}},"outputId":"669eca02-e051-4659-cdcf-ffec05869e75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test F1-score: 90.05%\n"]}]}]}